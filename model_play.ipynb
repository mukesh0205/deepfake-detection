{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"nYGefXtTJ0iS","executionInfo":{"status":"ok","timestamp":1679575714786,"user_tz":-330,"elapsed":10748,"user":{"displayName":"Surya S","userId":"06917879980776803843"}}},"outputs":[],"source":["import tensorflow as tf\n","import dlib\n","import cv2\n","import os\n","import numpy as np\n","from PIL import Image, ImageChops, ImageEnhance\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing.image import img_to_array, load_img"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C0odyi2fg1Vy","executionInfo":{"status":"ok","timestamp":1679575741829,"user_tz":-330,"elapsed":27047,"user":{"displayName":"Surya S","userId":"06917879980776803843"}},"outputId":"042bbbca-4bbc-43b3-e47f-f0c8ecd79bdc"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bUb7QAGRJ0iW","outputId":"db8ca35d-13bf-4734-87d5-fdd9660c26c7"},"outputs":[{"data":{"text/plain":["'2.0.0'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["tf.__version__"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"jBBbfE45J0iX","executionInfo":{"status":"ok","timestamp":1679575799308,"user_tz":-330,"elapsed":21033,"user":{"displayName":"Surya S","userId":"06917879980776803843"}}},"outputs":[],"source":["model = load_model('/content/drive/MyDrive/Velozity/fake detection/deepfake-detection-model.h5')"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"ZMTKIkHKJ0iY","outputId":"d5d372dc-d1a1-42fc-aeb1-4f6f1d69fd2e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679576905335,"user_tz":-330,"elapsed":11518,"user":{"displayName":"Surya S","userId":"06917879980776803843"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 142ms/step\n","[0 0]\n","1/1 [==============================] - 0s 129ms/step\n","[0 0]\n","1/1 [==============================] - 0s 129ms/step\n","[0 0]\n","1/1 [==============================] - 0s 155ms/step\n","[0 0]\n","1/1 [==============================] - 0s 205ms/step\n","[0 0]\n","1/1 [==============================] - 0s 216ms/step\n","[0 0]\n","1/1 [==============================] - 0s 125ms/step\n","[0 0]\n","1/1 [==============================] - 0s 128ms/step\n","[0 0]\n","1/1 [==============================] - 0s 129ms/step\n","[0 0]\n","1/1 [==============================] - 0s 147ms/step\n","[0 0]\n"]}],"source":["input_shape = (128, 128, 3)\n","pr_data = []\n","detector = dlib.get_frontal_face_detector()\n","cap = cv2.VideoCapture('/content/gpsxfxrjrr.mp4')\n","frameRate = cap.get(5)\n","while cap.isOpened():\n","    frameId = cap.get(1)\n","    ret, frame = cap.read()\n","    if ret != True:\n","        break\n","    if frameId % ((int(frameRate)+1)*1) == 0:\n","        face_rects, scores, idx = detector.run(frame, 0)\n","        for i, d in enumerate(face_rects):\n","            x1 = d.left()\n","            y1 = d.top()\n","            x2 = d.right()\n","            y2 = d.bottom()\n","            crop_img = frame[y1:y2, x1:x2]\n","            data = img_to_array(cv2.resize(crop_img, (128, 128))).flatten() / 255.0\n","            data = data.reshape(-1, 128, 128, 3)\n","            print(np.argmax(model.predict(data), axis=1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BSxixZOTJ0iY"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python [conda env:root] *","language":"python","name":"conda-root-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}